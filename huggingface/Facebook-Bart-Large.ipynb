{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9753ee1-d3ae-45f7-8099-05bfc5428835",
   "metadata": {},
   "source": [
    "## BART \n",
    "\n",
    "- BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder.\n",
    "- BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text.\n",
    "- BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering).\n",
    "\n",
    "https://huggingface.co/tasks/text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28365aaa-ef40-4752-a593-24da718c4eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartModel(\n",
      "  (shared): Embedding(50265, 1024, padding_idx=1)\n",
      "  (encoder): BartEncoder(\n",
      "    (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x BartEncoderLayer(\n",
      "        (self_attn): BartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): GELUActivation()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): BartDecoder(\n",
      "    (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x BartDecoderLayer(\n",
      "        (self_attn): BartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): GELUActivation()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): BartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# IMPORT THE REQUIRED LIBRARIES\n",
    "from transformers import BartTokenizer, BartModel\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "model = BartModel.from_pretrained('facebook/bart-large')\n",
    "\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82325f8f-8dfe-440e-b55c-f9d499ee5a5e",
   "metadata": {},
   "source": [
    "# 1 Text Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a327a9a-08e7-4fe3-ac5e-649341e401ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual text:\n",
      " I am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I’ve ever gotten to a college graduation. Today I want to tell you three stories from my life. That’s it. No big deal. Just three stories.The first story is about connecting the dots.I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out?It started before I was born. My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption. She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife. Except that when I popped out they decided at the last minute that they really wanted a girl. So my parents, who were on a waiting list, got a call in the middle of the night asking: “We have an unexpected baby boy; do you want him?” They said: “Of course.” My biological mother later found out that my mother had never graduated from college and that my father had never graduated from high school. She refused to sign the final adoption papers. She only relented a few months later when my parents promised that I would someday go to college.And 17 years later I did go to college. But I naively chose a college that was almost as expensive as Stanford, and all of my working-class parents’ savings were being spent on my college tuition. After six months, I couldn’t see the value in it. I had no idea what I wanted to do with my life and no idea how college was going to help me figure it out. And here I was spending all of the money my parents had saved their entire life. So I decided to drop out and trust that it would all work out OK. It was pretty scary at the time, but looking back it was one of the best decisions I ever made. The minute I dropped out I could stop taking the required classes that didn’t interest me, and begin dropping in on the ones that looked interesting.It\n",
      "Text Summary:\n",
      " [{'summary_text': 'I am honored to be with you today at your commencement from one of the finest universities in the world. Truth be told, this is the closest I’ve ever gotten to a college graduation.I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. I never graduated from college. So why did I drop out?It started before I was born. My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption. She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife. Except that when I popped out they decided at the last minute that they really wanted a girl. So my parents, who were on a waiting list, got a call in the middle of the night asking: “We have an unexpected baby boy;'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large\")\n",
    "\n",
    "file_path = r\"C:\\Users\\jayanti.prasad\\Data\\NLP_DATA\\steve_jobs_speech.txt\"\n",
    "with open (file_path,\"r\",encoding='utf-8') as fp:\n",
    "    data = fp.read()\n",
    "\n",
    "data = data.replace('\\r', '').replace('\\n', '')\n",
    "data = \" \".join(data.split(\" \")[:400])\n",
    "\n",
    "print(\"Actual text:\\n\",data)\n",
    "print(\"Text Summary:\\n\",summarizer(data, max_length=200, min_length=30, do_sample=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0f068-b5dc-4f59-a9fe-ef651197fa4d",
   "metadata": {},
   "source": [
    " # 2. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81a8cddc-efed-4c48-8c42-cb877cb75371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1024])\n",
      "[ 0.55122346  0.8389284  -1.4706675  ...  1.3124424  -0.2046631\n",
      "  0.23921812]\n",
      "[ 0.55122346  0.8389284  -1.4706675  ...  1.3124424  -0.2046631\n",
      "  0.23921812]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(last_hidden_states.shape)\n",
    "print(last_hidden_states[0,0,:].detach().numpy())\n",
    "print(outputs.last_hidden_state[0,0,:].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69919d-4b78-4acf-aa5b-a32d07eb8ec6",
   "metadata": {},
   "source": [
    "# 3. Text Classification\n",
    "\n",
    "Text Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8c1ea0a-6ac8-49b2-8cbb-3a644873a100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.42060524225234985}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model = \"facebook/bart-large\")\n",
    "results = classifier(\"A soccer game with multiple males playing. Some men are playing a sport.\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29735a9-a90f-4b8a-970e-0eaa4a1ee7a9",
   "metadata": {},
   "source": [
    "# 4. Question-Answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fbd7b91-6305-4dd5-bbb8-3d29ebfe90c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.3615689277648926}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model = \"facebook/bart-large\")\n",
    "result = classifier(\"Where is the capital of France?, Paris is the capital of France.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465441c6-81e3-4187-8953-a9ff4b487d2f",
   "metadata": {},
   "source": [
    "# 2. Sentiment Aanalysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27a32763-5902-4f21-9bc6-3c114d2d6be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.38467931747436523}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\",model = \"facebook/bart-large\")\n",
    "result = classifier(\"I loved Star Wars so much!\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2d968-53e8-40ce-89fa-52675b4b49bf",
   "metadata": {},
   "source": [
    "# 6 Grammatical Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "064180c9-6af4-40f6-8af5-9797bc9ee301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_2', 'score': 0.4962370693683624}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = pipeline(\"text-classification\", model = \"facebook/bart-large\")\n",
    "result = classifier(\"I will walk to home when I went through the bus.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16e7c3-e4fd-4633-9429-827fe81b92a0",
   "metadata": {},
   "source": [
    "# 3 Text Generation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33aae9d5-6643-47ba-93ff-f73e6a0f93c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448ac79e8b84459ca4ddc14f071e4cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df28f73bbe88409c9c9ca186b71ceefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a4b4d75e7646f6bb168aff96995a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8460a6817b4543eb8b15064315b5c57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cf948b3b834f41bb01c024b4b6ba0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Hello, I'm a language modeler. You know your code. Yes. Well, I just wrote a bunch of helper functions and I wrote the\"}, {'generated_text': 'Hello, I\\'m a language model for human beings, a tool of our imagination, a model for the history of this world.\"'}, {'generated_text': \"Hello, I'm a language model. I don't know how it's gonna feel to write the typechecker. This just goes to show how\"}]\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation',model = \"gpt2\")\n",
    "result = generator(\"Hello, I'm a language model\", max_length = 30, num_return_sequences=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "941b9429-4e28-45b3-b336-260770c7158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartModel(\n",
      "  (shared): Embedding(50265, 1024, padding_idx=1)\n",
      "  (encoder): BartEncoder(\n",
      "    (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x BartEncoderLayer(\n",
      "        (self_attn): BartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation_fn): GELUActivation()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): BartDecoder(\n",
      "    (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "    (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x BartDecoderLayer(\n",
      "        (self_attn): BartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_fn): GELUActivation()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): BartAttention(\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c49ba-573b-4b6c-b177-5efd9eb83be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
