{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff068e3-118d-4706-bceb-8036d54b55d7",
   "metadata": {},
   "source": [
    "# OpenAI GPT2\n",
    "\n",
    "OpenAI GPT-2 model was proposed in Language Models are Unsupervised Multitask Learners by Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei and Ilya Sutskever from OpenAI. Itâ€™s a causal (unidirectional) transformer pretrained using language modeling on a very large corpus of ~40 GB of text data.\n",
    "\n",
    "GPT-2 is a large transformer-based language model with 1.5 billion parameters, trained on a dataset[1] of 8 million web pages. GPT-2 is trained with a simple objective: predict the next word, given all of the previous words within some text. The diversity of the dataset causes this simple goal to contain naturally occurring demonstrations of many tasks across diverse domains. GPT-2 is a direct scale-up of GPT, with more than 10X the parameters and trained on more than 10X the amount of data.\n",
    "\n",
    "Reference : https://huggingface.co/docs/transformers/model_doc/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ce63689-c765-49f6-b4f6-8e8d7fd9aa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Configuartion:\n",
      "\n",
      "GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the model architecture \n",
    "from transformers import GPT2Model, GPT2Config\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "print(model)\n",
    "config = GPT2Config()\n",
    "\n",
    "print(\"Configuartion:\\n\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd48fab4-4d61-4e23-8866-41bde7dc72d1",
   "metadata": {},
   "source": [
    "# GPT2 Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64387ad9-f22c-4377-88f1-5b12c82fd52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 995]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('gpt2_vocab\\\\vocab.json', 'gpt2_vocab\\\\merges.txt')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check Tokenizer \n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "print(tokenizer(\"Hello world\")[\"input_ids\"])\n",
    "\n",
    "tokenizer.save_vocabulary(\"gpt2_vocab\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193fc183-5e9e-4519-aecb-a7fd4975aded",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0a2f27-5240-47bb-94ce-1453d08daaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-9.0342e-06, -1.4021e-01, -2.0845e-01,  ..., -1.5329e-01,\n",
      "          -6.7826e-02, -1.9630e-01],\n",
      "         [ 4.1949e-01,  2.3525e-01,  3.4816e-01,  ...,  4.5322e-02,\n",
      "           1.5447e-01,  1.9547e-02],\n",
      "         [-7.0056e-02,  2.6082e-01, -2.9146e-01,  ...,  9.0979e-02,\n",
      "           4.9659e-01, -4.1824e-01],\n",
      "         [-1.9695e-01, -2.9247e-01, -1.4119e-01,  ..., -8.9255e-02,\n",
      "          -2.2392e-01,  1.2212e-01],\n",
      "         [-6.4193e-01, -1.0236e-01, -4.2129e-01,  ...,  6.8697e-02,\n",
      "          -5.1117e-01,  5.0044e-01],\n",
      "         [ 4.1286e-03, -3.1454e-02, -1.0823e+00,  ..., -5.0159e-02,\n",
      "          -3.0878e-02,  4.3480e-01]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2Model\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df0e5c3f-66db-4acf-89c0-4988f2393c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at gpt2 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=tensor(nan, grad_fn=<DivBackward0>), start_logits=tensor([[ 3.0386,  9.8525,  4.7776,  6.5073,  8.6920,  9.9764,  5.4821, 13.4301,\n",
      "          8.4862,  9.6751,  9.9907,  9.7177,  9.0636]],\n",
      "       grad_fn=<CloneBackward0>), end_logits=tensor([[-0.6750, -1.9020, -1.1939, -0.0285, -1.6016, -0.7465, -1.4319, -3.7202,\n",
      "         -2.1298, -1.9746, -1.6999, -1.5966, -1.2244]],\n",
      "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2ForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2ForQuestionAnswering.from_pretrained(\"gpt2\")\n",
    "\n",
    "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "\n",
    "inputs = tokenizer(question, text, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "\n",
    "# target is \"nice puppet\"\n",
    "target_start_index = torch.tensor([14])\n",
    "target_end_index = torch.tensor([15])\n",
    "\n",
    "outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)\n",
    "loss = outputs.loss\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a817bc5-62a1-464b-9985-8f6ce91196ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForQuestionAnswering(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe1545-48e3-4a2c-9eaa-84403af5e53e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
